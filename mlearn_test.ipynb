{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把这文件放在和mlearn/同一层文件夹运行\n",
    "## 不然import会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlearn\n",
    "from mlearn import functional as F\n",
    "from mlearn import layers\n",
    "from mlearn.optimizers import SGD, RMSProp, Momentum\n",
    "from torchvision import datasets,transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlearn import DataLoader\n",
    "from mlearn import pre as P\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"datasets\", train=True, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"datasets\", train=False, download=True,\n",
    "                     transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "pre = [P.normalize_MinMax]\n",
    "trainset = DataLoader((train.data,train.targets),batch_size=32,shuffle=True,\n",
    "                      preprocessing=pre)\n",
    "testset = DataLoader((test.data, test.targets), batch_size=32, shuffle=True,\n",
    "                    preprocessing=pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(mlearn.Module):\n",
    "    def __init__(self):\n",
    "        self.dense1 = layers.Dense(784,10)\n",
    "        self.dense2 = layers.Dense(300,150)\n",
    "        self.dense3 = layers.Dense(150,10)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        o = self.dense1(inputs)\n",
    "        o = F.relu(o)\n",
    "        o = self.dense2(o)\n",
    "        o = F.tanh(o)\n",
    "        o = self.dense1(inputs)\n",
    "        return ((o))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function cross_entropy.<locals>.grad_fn at 0x7fc093bd3560>\n",
      "<function _add.<locals>.grad_fn1 at 0x7fc093bd3050>\n",
      "<function _matmul.<locals>.grad_fn2 at 0x7fc093bd30e0>\n",
      "<function _add.<locals>.grad_fn2 at 0x7fc093bd3170>\n",
      "(10,)\n",
      "(784, 10)\n",
      "<function cross_entropy.<locals>.grad_fn at 0x7fc093ca24d0>\n",
      "<function _add.<locals>.grad_fn1 at 0x7fc093ca2680>\n",
      "<function _matmul.<locals>.grad_fn2 at 0x7fc093ca2440>\n",
      "<function _add.<locals>.grad_fn2 at 0x7fc093ca2320>\n",
      "(10,)\n",
      "(784, 10)\n",
      "<function cross_entropy.<locals>.grad_fn at 0x7fc093ca2710>\n",
      "<function _add.<locals>.grad_fn1 at 0x7fc093ca2830>\n",
      "<function _matmul.<locals>.grad_fn2 at 0x7fc093ca2950>\n",
      "<function _add.<locals>.grad_fn2 at 0x7fc093ca2560>\n",
      "(10,)\n",
      "(784, 10)\n",
      "<function cross_entropy.<locals>.grad_fn at 0x7fc093ca2440>\n",
      "<function _add.<locals>.grad_fn1 at 0x7fc093ca24d0>\n",
      "<function _matmul.<locals>.grad_fn2 at 0x7fc093ca29e0>\n",
      "<function _add.<locals>.grad_fn2 at 0x7fc093ca2680>\n",
      "(10,)\n",
      "(784, 10)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Stop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e92e8a3fd5f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#         shapes = optimizer.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#         running_loss += loss.data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Stop"
     ]
    }
   ],
   "source": [
    "hist = []\n",
    "net = Net()\n",
    "optimizer = SGD(net,0.001)\n",
    "EPOCHS = 1\n",
    "net.zero_grad()\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    bar = \" \"*20\n",
    "    for i, batch in enumerate(trainset, 0):\n",
    "        features, labels = batch\n",
    "        net.zero_grad()\n",
    "        predict = net(features.reshape(-1,784))\n",
    "        loss = F.cross_entropy(predict, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i==3:\n",
    "            raise RuntimeError(\"Stop\")\n",
    "        shapes = optimizer.step()\n",
    "        running_loss += loss.data\n",
    "        print(f\"\\r{epoch+1}/{EPOCHS} Batch %-4d/1874  [{bar}] -> Loss %.5f\"%(i,loss.data), end=\"\")\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "print('trainning completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.13019\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for batch in testset:\n",
    "    features, labels = batch\n",
    "    o = net(features.reshape(-1,784))\n",
    "    predict = []\n",
    "    for x in o.data:\n",
    "        predict.append(np.argmax(x))\n",
    "    for b in predict == labels.data:\n",
    "        if b:\n",
    "            correct += 1\n",
    "    total += 32\n",
    "print(\"Accuracy %.5f\"%(correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 60000/60000."
     ]
    }
   ],
   "source": [
    "\n",
    "num_episodes = 60000\n",
    "for i_episode in range(1, num_episodes + 1):\n",
    "    # Print out which episode we're on, useful for debugging.\n",
    "    if i_episode % 1000 == 0:\n",
    "        print(\"\\rEpisode {}/{}.\".format(i_episode, num_episodes), end=\"\")\n",
    "        sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ----------------------------------------]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "toolbar_width = 40\n",
    "\n",
    "# setup toolbar\n",
    "sys.stdout.write(\"[%s]\" % (\" \" * toolbar_width))\n",
    "sys.stdout.flush()\n",
    "sys.stdout.write(\"\\b\" * (toolbar_width+1)) # return to start of line, after '['\n",
    "\n",
    "for i in range(toolbar_width):\n",
    "    time.sleep(0.1) # do real work here\n",
    "    # update the bar\n",
    "    sys.stdout.write(\"-\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "sys.stdout.write(\"]\\n\") # this ends the progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
