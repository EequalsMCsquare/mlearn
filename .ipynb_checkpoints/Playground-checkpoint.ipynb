{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import Tensor, Module, Dense, SGD\n",
    "from autograd import tensor\n",
    "from autograd import function as F\n",
    "from autograd import utils\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repr(F.softmax(Tensor(rand),dim=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F.softmax(Tensor(rand),dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\"Stop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"../\",train=True,download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"../\",train=False,download=True)\n",
    "\n",
    "trainset_features = Tensor(train.data.reshape(-1,784))\n",
    "trainset_targets = Tensor(utils.one_hot(train.targets))\n",
    "\n",
    "testset_features = Tensor(test.data.reshape(-1,784))\n",
    "testset_labels = Tensor(test.targets)\n",
    "classes = train.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        self.dense1 = Dense(784,500)\n",
    "        self.dense2 = Dense(500,150)\n",
    "        self.dense3 = Dense(150,64)\n",
    "        self.dense4 = Dense(64,10)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        o = self.dense1(inputs)\n",
    "        o = F.relu(o)\n",
    "        o = self.dense2(o)\n",
    "        o = F.relu(o)\n",
    "        o = self.dense3(o)\n",
    "        o = F.tanh(o)\n",
    "        o = self.dense4(o)\n",
    "        return F.softmax(o,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(0.01)\n",
    "net = Net()\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.0008761900354396907\n",
      "Loss 0.0007757721553487097\n",
      "Loss 0.0009739342203428187\n",
      "Loss 0.0008694288514060299\n",
      "Loss 0.0008829632696520705\n"
     ]
    }
   ],
   "source": [
    "starts = np.arange(0,trainset_features.shape[0],batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "    np.random.shuffle(starts)\n",
    "    for start in starts:\n",
    "        running_loss = 0\n",
    "        net.zero_grad()\n",
    "        end = start + batch_size\n",
    "        inputs = trainset_features[start:end]\n",
    "        predict = net(inputs)\n",
    "        labels = trainset_targets[start:end]\n",
    "        error = predict - labels\n",
    "        loss = (error**2).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step(net)\n",
    "        running_loss += loss.data \n",
    "    print(\"Loss\", running_loss / 60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimize a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor([10, -10, 10, -5, 6, 3, 1], requires_grad=True)\n",
    "\n",
    "# we want to minimize the sum of squares\n",
    "for i in range(100):\n",
    "    x.zero_grad()\n",
    "\n",
    "    sum_of_squares = (x * x).sum()  # is a 0-tensor\n",
    "    sum_of_squares.backward()\n",
    "\n",
    "    # ugly b/c we haven't implemented the stuff yet\n",
    "    delta_x = 0.1 * x.grad\n",
    "    x -= delta_x\n",
    "    if i % 20 == 19:\n",
    "        print(i, sum_of_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
